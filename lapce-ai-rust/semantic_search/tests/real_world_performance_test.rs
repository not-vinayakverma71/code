// REAL-WORLD PERFORMANCE TEST: ALL 6 TASKS WITH AWS TITAN
// Tests the complete integrated system with actual performance metrics

use lancedb::embeddings::compression::CompressedEmbedding;
use lancedb::embeddings::hierarchical_cache::{HierarchicalCache, CacheConfig};
use lancedb::embeddings::mmap_storage::ConcurrentMmapStorage;
use lancedb::embeddings::aws_titan_production::{AwsTitanProductionEmbedder, AwsTier};
use lancedb::embeddings::embedder_interface::IEmbedder;
use lancedb::search::optimized_lancedb_storage::{OptimizedLanceStorage, OptimizedStorageConfig, EmbeddingMetadata};
use lancedb::search::query_optimizer::{QueryOptimizer, QueryOptimizerConfig};
use lancedb::Connection;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tempfile::tempdir;
use tokio::sync::RwLock;

// Real code samples for testing
const CODE_SAMPLES: &[&str] = &[
    // JavaScript/TypeScript
    "async function fetchUserProfile(userId: string): Promise<User> {
        const response = await fetch(`/api/users/${userId}`);
        if (!response.ok) throw new Error('User not found');
        return response.json();
    }",
    
    // Rust
    "impl<T: Clone> Vec<T> {
        pub fn extend_from_slice(&mut self, other: &[T]) {
            self.reserve(other.len());
            for item in other {
                self.push(item.clone());
            }
        }
    }",
    
    // Python
    "def fibonacci_generator():
        a, b = 0, 1
        while True:
            yield a
            a, b = b, a + b",
    
    // SQL
    "SELECT c.customer_name, COUNT(o.order_id) as order_count,
            SUM(o.total_amount) as total_spent
     FROM customers c
     LEFT JOIN orders o ON c.customer_id = o.customer_id
     WHERE o.order_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
     GROUP BY c.customer_id
     HAVING order_count > 5
     ORDER BY total_spent DESC
     LIMIT 100",
    
    // Go
    "func processItems(ctx context.Context, items []Item) error {
        errCh := make(chan error, len(items))
        var wg sync.WaitGroup
        for _, item := range items {
            wg.Add(1)
            go func(it Item) {
                defer wg.Done()
                if err := processItem(ctx, it); err != nil {
                    errCh <- err
                }
            }(item)
        }
        wg.Wait()
        close(errCh)
        return <-errCh
    }",
    
    // Java
    "public class ConcurrentCache<K, V> {
        private final Map<K, V> cache = new ConcurrentHashMap<>();
        private final ReadWriteLock lock = new ReentrantReadWriteLock();
        
        public V get(K key) {
            lock.readLock().lock();
            try {
                return cache.get(key);
            } finally {
                lock.readLock().unlock();
            }
        }
    }",
    
    // React Component
    "const UserDashboard = ({ userId }) => {
        const [user, setUser] = useState(null);
        const [loading, setLoading] = useState(true);
        
        useEffect(() => {
            fetchUserData(userId)
                .then(setUser)
                .finally(() => setLoading(false));
        }, [userId]);
        
        if (loading) return <Spinner />;
        return <DashboardLayout user={user} />;
    }",
    
    // Docker Compose
    "version: '3.8'
    services:
      postgres:
        image: postgres:14
        environment:
          POSTGRES_DB: myapp
          POSTGRES_USER: appuser
          POSTGRES_PASSWORD: ${DB_PASSWORD}
        volumes:
          - postgres_data:/var/lib/postgresql/data
        ports:
          - '5432:5432'
    volumes:
      postgres_data:",
    
    // Kubernetes
    "apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: web-app
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: web
      template:
        metadata:
          labels:
            app: web
        spec:
          containers:
          - name: app
            image: myapp:latest
            ports:
            - containerPort: 8080
            resources:
              limits:
                memory: '512Mi'
                cpu: '500m'",
    
    // GraphQL Schema
    "type User {
      id: ID!
      username: String!
      email: String!
      posts: [Post!]!
      createdAt: DateTime!
    }
    
    type Post {
      id: ID!
      title: String!
      content: String!
      author: User!
      comments: [Comment!]!
    }
    
    type Query {
      user(id: ID!): User
      post(id: ID!): Post
      searchPosts(query: String!): [Post!]!
    }",
];

#[tokio::test]
async fn test_real_world_performance() {
    println!("\n");
    println!("=============================================================");
    println!("       REAL-WORLD PERFORMANCE TEST WITH AWS TITAN");
    println!("=============================================================\n");
    
    // Check AWS credentials
    if std::env::var("AWS_ACCESS_KEY_ID").is_err() || 
       std::env::var("AWS_SECRET_ACCESS_KEY").is_err() {
        println!("‚ö†Ô∏è  AWS credentials not configured!");
        println!("   Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY");
        println!("   Skipping real API test...\n");
        return;
    }
    
    println!("‚úÖ AWS credentials detected\n");
    
    // Setup directories
    let temp_dir = tempdir().unwrap();
    let workspace_path = temp_dir.path().to_path_buf();
    let db_path = workspace_path.join("test.db");
    let cache_dir = workspace_path.join("cache");
    let mmap_path = workspace_path.join("embeddings.mmap");
    
    // ========================================
    // Initialize AWS Titan Embedder
    // ========================================
    println!("üöÄ Initializing AWS Titan Production Embedder...");
    
    let embedder = AwsTitanProductionEmbedder::new(
        AwsTier::Standard,  // 10 requests/sec, 40K tokens/min
        Some("amazon.titan-embed-text-v1".to_string()),
        Some("us-east-1".to_string()),
        Some(Duration::from_secs(30))
    ).await.unwrap();
    
    println!("  Model: amazon.titan-embed-text-v1");
    println!("  Region: us-east-1");
    println!("  Tier: Standard (10 req/s, 40K tokens/min)\n");
    
    // ========================================
    // TASK 1: ZSTD Compression Testing
    // ========================================
    println!("üì¶ TASK 1: ZSTD Compression with Real Embeddings");
    
    // Get a real embedding
    let test_text = CODE_SAMPLES[0];
    let response = embedder.embed(test_text.to_string()).await.unwrap();
    let embedding = response.embeddings;
    
    let original_size = embedding.len() * 4;
    let compressed = CompressedEmbedding::compress(&embedding).unwrap();
    let compressed_size = compressed.size_bytes();
    let compression_ratio = (original_size - compressed_size) as f64 / original_size as f64;
    
    // Verify lossless
    let decompressed = compressed.decompress().unwrap();
    let mut is_lossless = true;
    for (orig, decomp) in embedding.iter().zip(decompressed.iter()) {
        if orig.to_bits() != decomp.to_bits() {
            is_lossless = false;
            break;
        }
    }
    
    println!("  Embedding dimensions: {}", embedding.len());
    println!("  Original size: {} bytes", original_size);
    println!("  Compressed size: {} bytes", compressed_size);
    println!("  Compression ratio: {:.1}%", compression_ratio * 100.0);
    println!("  Data integrity: {}", if is_lossless { "‚úÖ LOSSLESS" } else { "‚ùå LOSSY" });
    println!("  Success Metric (50% compression): {}\n", 
        if compression_ratio >= 0.5 { "‚úÖ ACHIEVED" } else { "‚ö†Ô∏è PARTIAL" });
    
    // ========================================
    // TASK 2: Memory-Mapped Storage
    // ========================================
    println!("üíæ TASK 2: Memory-Mapped Storage Performance");
    
    let mmap_storage = ConcurrentMmapStorage::create(
        mmap_path.to_str().unwrap(),
        100,
        embedding.len()
    ).unwrap();
    
    // Store multiple compressed embeddings
    let mut compressed_embeddings = Vec::new();
    for (i, code) in CODE_SAMPLES.iter().take(10).enumerate() {
        let resp = embedder.embed(code.to_string()).await.unwrap();
        let comp = CompressedEmbedding::compress(&resp.embeddings).unwrap();
        mmap_storage.store_compressed(i, &comp).await.unwrap();
        compressed_embeddings.push(comp);
    }
    
    // Measure access latency
    let mut access_times = Vec::new();
    for i in 0..10 {
        let start = Instant::now();
        let _ = mmap_storage.get_compressed(i).await.unwrap();
        access_times.push(start.elapsed());
    }
    
    let avg_access = access_times.iter().sum::<Duration>() / access_times.len() as u32;
    let min_access = access_times.iter().min().unwrap();
    let max_access = access_times.iter().max().unwrap();
    
    println!("  Stored 10 real embeddings");
    println!("  Average access: {:?}", avg_access);
    println!("  Min access: {:?}", min_access);
    println!("  Max access: {:?}", max_access);
    println!("  Success Metric (< 100Œºs): {}\n",
        if avg_access < Duration::from_micros(100) { "‚úÖ ACHIEVED" } else { "‚ö†Ô∏è PARTIAL" });
    
    // ========================================
    // TASK 3: Hierarchical Cache
    // ========================================
    println!("üîÑ TASK 3: Hierarchical Cache System");
    
    let cache_config = CacheConfig {
        l1_max_bytes: 2_000_000,  // 2MB L1
        l2_max_bytes: 5_000_000,  // 5MB L2  
        l3_enabled: true,
        ttl: Duration::from_secs(300),
    };
    
    let cache = HierarchicalCache::new(
        cache_dir.to_str().unwrap(),
        cache_config
    ).unwrap();
    
    // Populate cache with real embeddings
    for (i, code) in CODE_SAMPLES.iter().enumerate() {
        let key = format!("code_{}", i);
        let resp = embedder.embed(code.to_string()).await.unwrap();
        cache.put(key, resp.embeddings).await.unwrap();
    }
    
    // Test cache performance
    let mut l1_hits = 0;
    let mut l2_hits = 0;
    let mut l3_hits = 0;
    
    for i in 0..CODE_SAMPLES.len() {
        let key = format!("code_{}", i);
        let _ = cache.get(&key).await.unwrap();
    }
    
    let stats = cache.get_stats();
    let l1_hit_rate = cache.l1_hit_rate();
    
    println!("  Total embeddings cached: {}", CODE_SAMPLES.len());
    println!("  L1 hits: {}, misses: {}", stats.l1_hits, stats.l1_misses);
    println!("  L2 hits: {}, misses: {}", stats.l2_hits, stats.l2_misses);
    println!("  L3 hits: {}", stats.l3_hits);
    println!("  L1 hit rate: {:.1}%", l1_hit_rate * 100.0);
    println!("  Success Metric (95% L1 hit): {}\n",
        if l1_hit_rate >= 0.95 { 
            "‚úÖ ACHIEVED".to_string() 
        } else { 
            format!("‚ö†Ô∏è {:.1}% achieved", l1_hit_rate * 100.0) 
        });
    
    // ========================================
    // TASK 4: API Integration (already using real AWS Titan)
    // ========================================
    println!("üîó TASK 4: Embedding API Integration");
    println!("  ‚úÖ Using real AWS Titan embeddings throughout");
    println!("  ‚úÖ Seamless integration achieved\n");
    
    // ========================================
    // TASK 5: LanceDB Storage Optimization
    // ========================================
    println!("‚ö° TASK 5: Optimized LanceDB Storage");
    
    let connection = lancedb::connect(db_path.to_str().unwrap())
        .execute()
        .await
        .unwrap();
    
    let storage_config = OptimizedStorageConfig {
        enable_mmap: true,
        store_compressed: true,
        ivf_partitions: 16,  // Smaller for test dataset
        pq_subvectors: 96,
        pq_bits: 8,
        batch_size: 50,
        nprobes: 5,
        ..Default::default()
    };
    
    let mut storage = OptimizedLanceStorage::new(
        Arc::new(connection.clone()),
        storage_config
    ).await.unwrap();
    
    // Create table and store real embeddings
    let table = storage.create_optimized_table("code_embeddings", embedding.len())
        .await
        .unwrap();
    
    let mut batch_embeddings = Vec::new();
    let mut batch_metadata = Vec::new();
    
    for (i, code) in CODE_SAMPLES.iter().enumerate() {
        let resp = embedder.embed(code.to_string()).await.unwrap();
        let compressed = CompressedEmbedding::compress(&resp.embeddings).unwrap();
        
        batch_embeddings.push(compressed);
        batch_metadata.push(EmbeddingMetadata {
            id: format!("sample_{}", i),
            path: format!("file_{}.rs", i),
            content: code[..100.min(code.len())].to_string(),
            language: Some("mixed".to_string()),
            start_line: i as i32,
            end_line: (i + 50) as i32,
        });
    }
    
    storage.store_compressed_batch(&table, batch_embeddings, batch_metadata)
        .await
        .unwrap();
    
    // Test query latency
    let query_text = "async function with error handling";
    let query_resp = embedder.embed(query_text.to_string()).await.unwrap();
    
    let mut query_times = Vec::new();
    for _ in 0..5 {
        let start = Instant::now();
        let results = storage.query_compressed(
            &table,
            &query_resp.embeddings,
            5
        ).await.unwrap();
        query_times.push(start.elapsed());
    }
    
    let avg_query_time = query_times.iter().sum::<Duration>() / query_times.len() as u32;
    
    println!("  Stored {} real embeddings", CODE_SAMPLES.len());
    println!("  Average query latency: {:?}", avg_query_time);
    println!("  Min query time: {:?}", query_times.iter().min().unwrap());
    println!("  Max query time: {:?}", query_times.iter().max().unwrap());
    println!("  Success Metric (< 5ms): {}\n",
        if avg_query_time < Duration::from_millis(5) { 
            "‚úÖ ACHIEVED".to_string() 
        } else {
            format!("‚ö†Ô∏è {:?} achieved", avg_query_time)
        });
    
    // ========================================
    // TASK 6: Query Optimization
    // ========================================
    println!("üöÄ TASK 6: Query Optimization Performance");
    
    let optimizer_config = QueryOptimizerConfig {
        enable_caching: true,
        enable_batching: true,
        enable_compressed_search: true,
        batch_size: 5,
        max_concurrent: 50,
        cache_ttl: 300,
        ..Default::default()
    };
    
    let optimizer = QueryOptimizer::new(
        Arc::new(connection),
        Arc::new(storage),
        optimizer_config
    ).await.unwrap();
    
    // Prepare diverse query embeddings
    let query_texts = vec![
        "database connection pooling",
        "async await javascript",
        "rust memory safety",
        "SQL JOIN performance",
        "kubernetes deployment",
    ];
    
    let mut query_embeddings = Vec::new();
    for text in &query_texts {
        let resp = embedder.embed(text.to_string()).await.unwrap();
        query_embeddings.push(resp.embeddings);
    }
    
    // Run performance test
    let test_start = Instant::now();
    let test_duration = Duration::from_secs(3);
    let mut query_count = 0;
    let mut individual_times = Vec::new();
    
    while test_start.elapsed() < test_duration {
        let query_idx = query_count % query_embeddings.len();
        let query_embedding = &query_embeddings[query_idx];
        
        let query_start = Instant::now();
        let _ = optimizer.query(&table, query_embedding, 5).await.unwrap();
        individual_times.push(query_start.elapsed());
        
        query_count += 1;
    }
    
    let actual_duration = test_start.elapsed();
    let qps = query_count as f64 / actual_duration.as_secs_f64();
    
    let avg_individual = individual_times.iter().sum::<Duration>() / individual_times.len() as u32;
    let metrics = optimizer.get_metrics().await;
    
    println!("  Total queries executed: {}", query_count);
    println!("  Test duration: {:?}", actual_duration);
    println!("  Queries per second: {:.1}", qps);
    println!("  Average query time: {:?}", avg_individual);
    println!("  Cache hit rate: {:.1}%", metrics.cache_hit_rate() * 100.0);
    println!("  P50 latency: {}ms", metrics.p50_latency_ms);
    println!("  P95 latency: {}ms", metrics.p95_latency_ms);
    println!("  Success Metric (100 qps): {}\n",
        if qps >= 100.0 { 
            "‚úÖ ACHIEVED".to_string() 
        } else {
            format!("‚ö†Ô∏è {:.1} qps achieved", qps)
        });
    
    // ========================================
    // FINAL SUMMARY
    // ========================================
    println!("=============================================================");
    println!("                  PERFORMANCE SUMMARY");
    println!("=============================================================\n");
    
    let results = vec![
        ("TASK 1: ZSTD Compression", format!("{:.0}%", compression_ratio * 100.0), 
         compression_ratio >= 0.5, "50% compression"),
        
        ("TASK 2: Memory-Mapped Storage", format!("{:?}", avg_access),
         avg_access < Duration::from_micros(100), "< 100Œºs access"),
        
        ("TASK 3: Hierarchical Cache", format!("{:.1}%", l1_hit_rate * 100.0),
         l1_hit_rate >= 0.95, "95% L1 hit rate"),
        
        ("TASK 4: API Integration", "AWS Titan".to_string(),
         true, "Seamless integration"),
        
        ("TASK 5: LanceDB Storage", format!("{:?}", avg_query_time),
         avg_query_time < Duration::from_millis(5), "< 5ms query"),
        
        ("TASK 6: Query Optimization", format!("{:.1} qps", qps),
         qps >= 100.0, "100 queries/second"),
    ];
    
    for (task, achieved, success, target) in results {
        println!("{}", task);
        println!("  Target: {}", target);
        println!("  Achieved: {}", achieved);
        println!("  Status: {}\n", if success { "‚úÖ SUCCESS" } else { "‚ö†Ô∏è PARTIAL" });
    }
    
    println!("=============================================================");
    println!("  All 6 tasks integrated and tested with real AWS Titan API");
    println!("=============================================================\n");
}

#[tokio::test]
async fn test_memory_usage_comparison() {
    println!("\nüìä MEMORY USAGE COMPARISON WITH REAL DATA\n");
    
    if std::env::var("AWS_ACCESS_KEY_ID").is_err() {
        println!("Skipping - AWS credentials not available");
        return;
    }
    
    let embedder = AwsTitanProductionEmbedder::new(
        AwsTier::Standard,
        Some("amazon.titan-embed-text-v1".to_string()),
        Some("us-east-1".to_string()),
        None
    ).await.unwrap();
    
    println!("Generating 50 real embeddings from AWS Titan...");
    
    let mut raw_total = 0;
    let mut compressed_total = 0;
    
    for i in 0..50 {
        let text = format!("Sample code snippet number {} with various programming constructs", i);
        let resp = embedder.embed(text).await.unwrap();
        
        let raw_size = resp.embeddings.len() * 4;
        let compressed = CompressedEmbedding::compress(&resp.embeddings).unwrap();
        let comp_size = compressed.size_bytes();
        
        raw_total += raw_size;
        compressed_total += comp_size;
        
        if (i + 1) % 10 == 0 {
            println!("  Processed {} embeddings...", i + 1);
        }
    }
    
    let memory_reduction = (raw_total - compressed_total) as f64 / raw_total as f64;
    
    println!("\nResults:");
    println!("  Raw embeddings: {:.2} MB", raw_total as f64 / 1_048_576.0);
    println!("  Compressed: {:.2} MB", compressed_total as f64 / 1_048_576.0);
    println!("  Memory reduction: {:.1}%", memory_reduction * 100.0);
    println!("  Target: 93% reduction");
    println!("  Status: {}", if memory_reduction >= 0.93 { 
        "‚úÖ TARGET ACHIEVED".to_string() 
    } else {
        format!("‚ö†Ô∏è {:.1}% achieved", memory_reduction * 100.0)
    });
}
