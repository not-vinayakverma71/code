# ğŸ” COMPREHENSIVE AI PROVIDERS ANALYSIS
## Status Report: What's Done vs What's Left

**Analysis Date:** 2025-10-01  
**Documentation Reference:** `docs/03-AI-PROVIDERS-CONSOLIDATED.md`  
**Codex TypeScript Source:** `/home/verma/lapce/Codex/packages/types/src/providers/`

---

## ğŸ“Š EXECUTIVE SUMMARY

### Overall Status: **15% Complete** âš ï¸

| Component | Specified | Implemented | Status |
|-----------|-----------|-------------|---------|
| **Core Architecture** | AiProvider trait with BoxStream | Simple Provider trait | âŒ **NOT STARTED** |
| **Streaming Infrastructure** | SSE decoder + JSON parser | None | âŒ **NOT STARTED** |
| **Provider Implementations** | 8+ providers with exact 1:1 ports | 15 stub providers | âš ï¸ **STUBS ONLY** |
| **Rate Limiting** | Adaptive per-provider | Basic token bucket | âš ï¸ **PARTIAL** |
| **Circuit Breaker** | Per-provider with states | Basic struct | âš ï¸ **PARTIAL** |
| **ProviderManager** | Dispatch + routing | Basic ProviderPool | âš ï¸ **PARTIAL** |
| **Testing** | 1:1 parity fixtures | None | âŒ **NOT STARTED** |

---

## ğŸ—ï¸ WHAT'S ACTUALLY IMPLEMENTED

### 1. Basic Provider Trait (WRONG ARCHITECTURE) âš ï¸

**Current Implementation:** `src/providers_openai.rs`
```rust
#[async_trait]
pub trait Provider: Send + Sync {
    fn name(&self) -> &str;
    fn models(&self) -> Vec<String>;
    async fn complete(&self, request: AIRequest) -> Result<ProviderResponse>;
    async fn stream(&self, request: AIRequest) -> Result<ProviderResponse>;  // âŒ Wrong!
    async fn health_check(&self) -> Result<()>;
}
```

**Problems:**
- âŒ `stream()` returns `ProviderResponse`, not a stream!
- âŒ No `BoxStream<'static, Result<StreamToken>>`
- âŒ No support for SSE parsing
- âŒ No capability system
- âŒ Missing `count_tokens()`, `list_models()`

**Required Architecture:** (from doc lines 30-45)
```rust
#[async_trait]
pub trait AiProvider: Send + Sync + 'static {
    fn name(&self) -> &'static str;
    async fn health_check(&self) -> Result<HealthStatus>;
    async fn complete(&self, request: CompletionRequest) -> Result<CompletionResponse>;
    async fn complete_stream(&self, request: CompletionRequest) 
        -> Result<BoxStream<'static, Result<StreamToken>>>;  // âœ… Real streaming!
    async fn chat(&self, request: ChatRequest) -> Result<ChatResponse>;
    async fn chat_stream(&self, request: ChatRequest) 
        -> Result<BoxStream<'static, Result<StreamToken>>>;
    async fn list_models(&self) -> Result<Vec<Model>>;
    async fn count_tokens(&self, text: &str) -> Result<usize>;
    fn capabilities(&self) -> ProviderCapabilities;
}
```

### 2. Provider Implementations

#### âœ… Model Information (DONE)
- `src/providers_openai.rs` - GPT models defined âœ…
- `src/providers_anthropic.rs` - Claude models defined âœ…
- `src/providers_gemini.rs` - Gemini models defined âœ…
- `src/providers_bedrock.rs` - Bedrock models defined âœ…
- 11 other provider files with model definitions âœ…

#### âŒ Actual Implementations (NOT DONE)
All providers are **STUBS**:
```rust
// Example from providers_stub.rs
impl Provider for GeminiProvider {
    async fn complete(&self, request: AIRequest) -> Result<ProviderResponse> {
        Ok(ProviderResponse {
            content: format!("Mock Gemini response"),  // âŒ STUB!
            // ...
        })
    }
}
```

**What's Missing:**
1. âŒ Real HTTP requests to provider APIs
2. âŒ SSE streaming parsing
3. âŒ Provider-specific request formatting
4. âŒ Provider-specific response parsing
5. âŒ Error handling per provider
6. âŒ Authentication headers (Bearer, API keys, AWS SigV4)

### 3. OpenAI "Real" Implementation âš ï¸

**File:** `src/providers_openai_real.rs`

**Status:** Partial implementation exists but:
- âŒ Not using the correct trait
- âŒ Stream parsing is incomplete
- âŒ Not integrated with ProviderManager
- âŒ No SSE decoder
- âš ï¸ Basic HTTP request works

### 4. Rate Limiting âš ï¸

**File:** `src/rate_limiting.rs`

**What Works:**
- âœ… Token bucket algorithm implemented
- âœ… Async consume/try_consume methods

**What's Missing:**
- âŒ Not integrated per-provider
- âŒ No adaptive behavior
- âŒ No per-provider rate limit configuration
- âŒ No circuit breaker integration

### 5. Circuit Breaker âš ï¸

**File:** `src/provider_pool.rs` (lines 100+)

**What Exists:**
```rust
struct CircuitBreaker {
    state: Arc<RwLock<CircuitState>>,
    failure_count: Arc<AtomicU32>,
    threshold: u32,
}
```

**Problems:**
- âŒ Basic struct only, no implementation
- âŒ No Open/Closed/HalfOpen state machine
- âŒ No automatic recovery
- âŒ Not integrated with providers

### 6. Provider Pool âš ï¸

**File:** `src/provider_pool.rs`

**What Works:**
- âœ… Basic routing to providers
- âœ… Provider configuration
- âœ… Fallback logic exists

**What's Missing:**
- âŒ No ProviderManager as specified
- âŒ No health monitoring
- âŒ No DashMap for providers
- âŒ No metrics integration
- âŒ No concurrent provider selection

---

## âŒ WHAT'S COMPLETELY MISSING

### 1. Streaming Infrastructure (CRITICAL) âŒ

**Required:** (doc lines 194-209)
```rust
pub struct StreamProcessor {
    decoder: SseDecoder,
    parser: JsonStreamParser,
}

impl StreamProcessor {
    pub fn process_chunk(&mut self, chunk: &[u8]) -> Vec<StreamToken> {
        // decode without allocation
    }
}

pub struct SseDecoder {
    buffer: BytesMut,
    position: usize,
}
```

**Current Status:** âŒ **DOES NOT EXIST**
- No `StreamProcessor`
- No `SseDecoder`
- No `JsonStreamParser`
- No zero-allocation chunk processing

### 2. OpenAI Provider (Exact Port) âŒ

**Required:** (doc lines 88-112)
- âœ… Basic structure exists
- âŒ SSE format NOT matching exactly:
  ```
  data: {"id":"...","choices":[{"delta":{"content":"Hello"}}]}
  data: {"id":"...","choices":[{"delta":{"content":" world"}}]}
  data: [DONE]
  ```
- âŒ No streaming implementation with `BoxStream`
- âŒ Not using `Arc<reqwest::Client>` for connection reuse

### 3. Anthropic Provider (Exact Port) âŒ

**Required:** (doc lines 116-154)
- âœ… Model definitions exist
- âŒ Headers NOT implemented:
  ```rust
  "anthropic-version": "2023-06-01",
  "anthropic-beta": "prompt-caching-2024-07-31",
  "x-api-key": apiKey
  ```
- âŒ Event-based SSE NOT implemented:
  ```
  event: message_start
  event: content_block_delta
  event: message_stop
  ```
- âŒ No `format_messages()` for Human/Assistant formatting
- âŒ No `parse_sse_event()` method

### 4. Gemini Provider âŒ

**Required:** (doc lines 162-169)
- âœ… Model definitions exist
- âŒ Request format NOT implemented:
  ```json
  {
    "contents": [{ "parts": [{"text": "Hello"}], "role": "user" }],
    "generationConfig": { "temperature": 0.7, "maxOutputTokens": 2048 }
  }
  ```
- âŒ Different from OpenAI schema - needs custom formatting

### 5. AWS Bedrock Provider âŒ

**Required:** (doc lines 171-174)
- âœ… Model definitions exist
- âŒ AWS SigV4 signing NOT implemented
- âŒ Model-specific payloads (Claude/Titan/Llama) NOT implemented
- âŒ No AWS SDK integration

### 6. OpenRouter Provider âŒ

**Required:** (doc lines 176-182)
- âŒ File doesn't exist
- âŒ Special headers NOT implemented:
  ```
  "HTTP-Referer": "https://yourapp.com"
  "X-Title": "Your App Name"
  ```

### 7. xAI Provider âš ï¸

**File:** `src/providers_xai.rs` exists
- âœ… Model definitions
- âŒ Mostly OpenAI compatible but xAI-specific deviations not handled

### 8. Perplexity Provider âŒ

**Required:** (doc line 187-188)
- âŒ File doesn't exist
- âŒ Internet search and citations not implemented
- âŒ Citation format parsing not implemented

### 9. Groq Provider âš ï¸

**File:** `src/providers_groq.rs` exists
- âœ… Model definitions
- âŒ Ultra-fast endpoint optimizations NOT implemented

### 10. ProviderManager (CRITICAL) âŒ

**Required:** (doc lines 58-72)
```rust
pub struct ProviderManager {
    providers: DashMap<String, Arc<dyn AiProvider>>,
    default_provider: RwLock<String>,
    health_monitor: HealthMonitor,
    metrics: Arc<ProviderMetrics>,
}
```

**Current Status:** âŒ **DOES NOT EXIST**
- Current `ProviderPool` is NOT the same
- No `DashMap` for thread-safe provider access
- No health monitor
- No metrics specific to providers

### 11. ProviderRegistry âŒ

**Required:** (doc lines 74-84)
```rust
pub struct ProviderRegistry {
    providers: HashMap<String, Box<dyn AiProvider>>,
}

impl ProviderRegistry {
    pub fn new() -> Self {
        // register all providers exactly as TS
    }
}
```

**Current Status:** âŒ **DOES NOT EXIST**

### 12. Testing Infrastructure âŒ

**Required:** (doc lines 225-235)
- âŒ No character-by-character streaming tests
- âŒ No header comparison tests
- âŒ No TypeScript fixture comparisons
- âŒ No load tests at 1K concurrent
- âŒ No test files for providers

```rust
#[tokio::test]
async fn provider_streaming_matches_ts() {
    // compare fixtures 1:1
}
```

---

## ğŸ“‹ WHAT NEEDS TO BE DONE (PRIORITY ORDER)

### ğŸ”´ CRITICAL - Phase 1 (2-3 weeks)

#### 1. Implement Core Architecture (Week 1)
- [ ] Create `AiProvider` trait with `BoxStream` support
- [ ] Implement `StreamProcessor` with SSE decoder
- [ ] Implement `JsonStreamParser` for zero-allocation parsing
- [ ] Create `ProviderManager` with DashMap
- [ ] Create `ProviderRegistry`
- [ ] Implement `ProviderCapabilities` struct

**Estimated Lines:** ~800-1000 lines

#### 2. Implement OpenAI Provider (Week 1)
- [ ] Port from `/home/verma/lapce/Codex/packages/types/src/providers/openai.ts`
- [ ] Exact SSE streaming format
- [ ] Use `Arc<reqwest::Client>`
- [ ] Implement retry logic
- [ ] Character-for-character match with TS

**Estimated Lines:** ~400-500 lines

#### 3. Implement Anthropic Provider (Week 2)
- [ ] Port from Codex `anthropic.ts`
- [ ] Event-based SSE parsing
- [ ] Special headers (anthropic-version, x-api-key)
- [ ] Human/Assistant message formatting
- [ ] Prompt caching support

**Estimated Lines:** ~500-600 lines

#### 4. Streaming Tests (Week 2)
- [ ] Create test fixtures from TypeScript
- [ ] Character-by-character streaming comparison
- [ ] Header validation tests
- [ ] Error message matching tests

**Estimated Lines:** ~300-400 lines test code

### ğŸŸ¡ HIGH PRIORITY - Phase 2 (1-2 weeks)

#### 5. Gemini Provider (Week 3)
- [ ] Port from Codex `gemini.ts`
- [ ] Implement `contents` â†’ `parts` â†’ `text` format
- [ ] Different request schema from OpenAI

**Estimated Lines:** ~400-500 lines

#### 6. AWS Bedrock Provider (Week 3)
- [ ] Port from Codex `bedrock.ts`
- [ ] AWS SigV4 signing
- [ ] Model-specific payloads (Claude/Titan/Llama)
- [ ] AWS SDK integration

**Estimated Lines:** ~600-800 lines

#### 7. Rate Limiting Integration (Week 4)
- [ ] Integrate `AdaptiveRateLimiter` per provider
- [ ] Circuit breaker state machine (Open/Closed/HalfOpen)
- [ ] Backoff and failover
- [ ] Per-provider configuration

**Estimated Lines:** ~300-400 lines

### ğŸŸ¢ MEDIUM PRIORITY - Phase 3 (1 week)

#### 8. Remaining Providers (Week 5)
- [ ] OpenRouter (special headers)
- [ ] xAI compatibility
- [ ] Perplexity (citations)
- [ ] Groq (optimizations)
- [ ] Other stubs â†’ real implementations

**Estimated Lines:** ~1500-2000 lines total

#### 9. Load Testing (Week 5)
- [ ] 1K concurrent request tests
- [ ] Memory profiling (< 8MB target)
- [ ] Latency benchmarks (< 5ms dispatch)
- [ ] Throughput tests

**Estimated Lines:** ~500 lines test code

### ğŸ”µ NICE TO HAVE - Phase 4

#### 10. Memory Optimization
- [ ] Object pools for request/response structs
- [ ] Reuse HTTP clients and buffers
- [ ] Arc for shared state

#### 11. Documentation
- [ ] Per-provider documentation
- [ ] Migration guide from TypeScript
- [ ] API examples

---

## ğŸ“Š DETAILED COMPARISON: SPEC VS REALITY

### Codex TypeScript Providers Available

Found in `/home/verma/lapce/Codex/packages/types/src/providers/`:
1. âœ… anthropic.ts (4,332 bytes)
2. âœ… bedrock.ts (12,779 bytes)
3. âœ… cerebras.ts (2,407 bytes)
4. âœ… chutes.ts (9,152 bytes)
5. âœ… claude-code.ts (3,510 bytes)
6. âœ… deepinfra.ts (511 bytes)
7. âœ… deepseek.ts (1,534 bytes)
8. âœ… doubao.ts (1,944 bytes)
9. âœ… featherless.ts (1,499 bytes)
10. âœ… fireworks.ts (4,574 bytes)
11. âœ… gemini-cli.ts (2,541 bytes)
12. âœ… gemini.ts (7,006 bytes)
13. âœ… glama.ts (1,222 bytes)
14. âœ… groq.ts (3,609 bytes)
15. âœ… huggingface.ts (577 bytes)
16. âœ… io-intelligence.ts (1,400 bytes)
17. âœ… lite-llm.ts (1,842 bytes)
18. âœ… lm-studio.ts (505 bytes)
19. âœ… mistral.ts (2,309 bytes)
20. âœ… moonshot.ts (869 bytes)
21. âœ… ollama.ts (425 bytes)
22. âœ… openai.ts (6,343 bytes) â­
23. âœ… openrouter.ts (4,174 bytes)
24. âœ… qwen-code.ts (1,180 bytes)
25. âœ… requesty.ts (651 bytes)
26. âœ… roo.ts (662 bytes)
27. âœ… sambanova.ts (2,576 bytes)
28. âœ… unbound.ts (357 bytes)
29. âœ… vertex.ts (8,695 bytes)
30. âœ… vscode-llm.ts (4,514 bytes)
31. âœ… xai.ts (2,500 bytes)
32. âœ… zai.ts (3,501 bytes)

**Total:** 33 providers available for porting!

### Rust Implementation Status

| Provider | TypeScript Source | Rust File | Status | Notes |
|----------|------------------|-----------|---------|-------|
| OpenAI | âœ… 6,343 bytes | providers_openai.rs | âš ï¸ STUB | Model defs only |
| Anthropic | âœ… 4,332 bytes | providers_anthropic.rs | âš ï¸ STUB | Model defs only |
| Gemini | âœ… 7,006 bytes | providers_gemini.rs | âš ï¸ STUB | Model defs only |
| Bedrock | âœ… 12,779 bytes | providers_bedrock.rs | âš ï¸ STUB | Model defs only |
| Cerebras | âœ… 2,407 bytes | providers_cerebras.rs | âš ï¸ STUB | Model defs only |
| Deepseek | âœ… 1,534 bytes | providers_deepseek.rs | âš ï¸ STUB | Model defs only |
| Fireworks | âœ… 4,574 bytes | providers_fireworks.rs | âš ï¸ STUB | Model defs only |
| Groq | âœ… 3,609 bytes | providers_groq.rs | âš ï¸ STUB | Model defs only |
| Mistral | âœ… 2,309 bytes | providers_mistral.rs | âš ï¸ STUB | Model defs only |
| Moonshot | âœ… 869 bytes | providers_moonshot.rs | âš ï¸ STUB | Model defs only |
| Ollama | âœ… 425 bytes | providers_ollama.rs | âš ï¸ STUB | Model defs only |
| Sambanova | âœ… 2,576 bytes | providers_sambanova.rs | âš ï¸ STUB | Model defs only |
| Vertex | âœ… 8,695 bytes | providers_vertex.rs | âš ï¸ STUB | Model defs only |
| xAI | âœ… 2,500 bytes | providers_xai.rs | âš ï¸ STUB | Model defs only |
| OpenRouter | âœ… 4,174 bytes | âŒ MISSING | âŒ NOT STARTED | - |
| Perplexity | ? | âŒ MISSING | âŒ NOT STARTED | - |
| **23 Others** | âœ… Available | âŒ MISSING | âŒ NOT STARTED | - |

---

## ğŸ’¾ CODE VOLUME ESTIMATE

### Already Written
- Model definitions: ~2,000 lines
- Basic stubs: ~1,500 lines
- ProviderPool: ~443 lines
- Rate limiting: ~385 lines
- **Total Existing:** ~4,328 lines

### Needs to Be Written
- Core architecture: ~1,000 lines
- Streaming infrastructure: ~800 lines
- 8 primary providers (real impl): ~4,000 lines
- Testing infrastructure: ~1,200 lines
- Rate limiting integration: ~400 lines
- Documentation: ~500 lines
- **Total Needed:** ~7,900 lines

### Grand Total: ~12,228 lines for complete implementation

---

## â±ï¸ TIME ESTIMATE

Based on 1:1 TypeScript translation requirement:

| Phase | Tasks | Estimated Time |
|-------|-------|----------------|
| **Phase 1** | Core architecture + OpenAI + Anthropic + Tests | 2-3 weeks |
| **Phase 2** | Gemini + Bedrock + Rate limiting | 1-2 weeks |
| **Phase 3** | 4 more providers + Load testing | 1 week |
| **Phase 4** | Optimization + Documentation | 1 week |
| **Total** | Complete AI Provider Implementation | **5-7 weeks** |

---

## ğŸ¯ SUCCESS CRITERIA (FROM DOC)

**ALL MUST BE MET:**
- [ ] Memory usage: < 8MB for all providers combined
- [ ] Latency: < 5ms dispatch overhead per request
- [ ] Streaming: Zero-allocation or near-zero, exact SSE formats
- [ ] Rate limiting: Adaptive per provider with circuit breaker
- [ ] Load: 1K concurrent requests sustained
- [ ] Parity: Character-for-character compatibility with TypeScript
- [ ] Tests: 100% behavior parity on mock and live endpoints

**Current Status:** 0/7 criteria met âŒ

---

## ğŸš¨ CRITICAL BLOCKERS

1. **No Real Streaming Implementation** - Cannot test or validate streaming behavior
2. **No SSE Decoder** - Cannot parse server-sent events from providers
3. **Wrong Trait Architecture** - Current `Provider` trait incompatible with spec
4. **No ProviderManager** - Cannot dispatch requests correctly
5. **No Testing Infrastructure** - Cannot validate 1:1 parity with TypeScript

---

## ğŸ“ RECOMMENDATIONS

### Immediate Actions (This Week)
1. **Stop using current Provider trait** - It's fundamentally wrong
2. **Implement AiProvider trait** with BoxStream support
3. **Create StreamProcessor** with SSE decoder
4. **Port OpenAI provider** line-by-line from TypeScript

### Next Steps (Weeks 2-3)
1. Implement Anthropic with event-based SSE
2. Create comprehensive streaming tests
3. Add rate limiting per provider
4. Implement circuit breaker state machine

### Long Term (Weeks 4-7)
1. Port remaining 6+ providers
2. Load testing at 1K concurrent
3. Memory optimization
4. Production deployment

---

## ğŸ“ˆ PROGRESS TRACKING

### Completion Percentage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI PROVIDERS IMPLEMENTATION: 15%               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Architecture:        â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%   â”‚
â”‚ Streaming:           â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%   â”‚
â”‚ OpenAI:              â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  15%   â”‚
â”‚ Anthropic:           â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%   â”‚
â”‚ Other Providers:     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%   â”‚
â”‚ Rate Limiting:       â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20%   â”‚
â”‚ Circuit Breaker:     â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  15%   â”‚
â”‚ Testing:             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%   â”‚
â”‚ Documentation:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  40%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ THE BOTTOM LINE

**What's Done:**
- âœ… Model definitions for 14 providers
- âœ… Basic provider configuration
- âœ… Token bucket rate limiter
- âœ… Documentation is excellent

**What's Left:**
- âŒ **EVERYTHING CRITICAL**
- âŒ Core architecture (wrong trait)
- âŒ Real streaming with SSE
- âŒ Actual API implementations
- âŒ Testing infrastructure
- âŒ 1:1 parity validation

**Reality Check:**
The current implementation has model definitions (data), but **NO ACTUAL PROVIDER LOGIC**. All providers return mock responses. The architecture doesn't match the specification. **Estimated 5-7 weeks of work remaining** for a production-ready, spec-compliant implementation.

---

**Next Step:** Start with Phase 1, Task 1 - Implement the correct `AiProvider` trait architecture with streaming support.
